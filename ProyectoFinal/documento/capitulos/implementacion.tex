\section{Arquitectura de la propuesta}

\section{Componentes}
Los componentes de la arquitectura se dividen en tres módulos principales. El primero corresponde al árbol de decisión, entrenado mediante la biblioteca scikit-learn de Python. El segundo está constituido por el código XDP, el cual incluye una parte autogenerada a partir del árbol de decisión. Finalmente, el tercer módulo es el entorno Mininet, empleado para la ejecución de pruebas en un entorno virtual local. Cabe destacar el fichero DecisionTree/arbolrw.py, encargado tanto del entrenamiento del árbol de decisión como de la autogeneración del código C, apoyándose para ello en una plantilla Jinja.

\subsection{Árbol de decisión}
El conjunto de datos empleado para el entrenamiento del árbol de decisión se ha generado a partir de un fichero CSV de 294,6 MB elaborado por el autor. Para su creación, se utilizó la versión más reciente del script pcap2csv.py, el cual permite la unión de dos o más ficheros PCAP en un único fichero CSV, así como la diferenciación entre paquetes de tráfico malicioso y legítimo mediante el uso de las banderas -l y -m. El script almacena únicamente información de los paquetes hasta el nivel de aplicación, sin analizar el contenido de este nivel, debido a la complejidad que supone obtener dichos datos en C a nivel de kernel.

El proceso de conversión comienza definiendo un diccionario con todas las posibles características que puede tener un paquete de red. A continuación, se leen los paquetes uno a uno y cada uno se procesa mediante una función que devuelve un diccionario en el que cada clave corresponde al nombre de una columna y cada valor al dato asociado a ese paquete en particular (véase un fragmento de esta función en\ref{pcap2dict}). En caso de que un paquete carezca de alguno de los campos —por ejemplo, los relativos a IP—, dichos valores se registran como None en lugar de omitirse, con el fin de mantener un formato uniforme en el CSV y evitar errores durante el procesamiento posterior.

Una vez transformado el paquete en diccionario, se añade al final la etiqueta ``Yes'' si corresponde a una muestra de ransomware, o ``No'' en caso contrario. Posteriormente, el diccionario se incorpora a un array. Cuando dicho array alcanza los 1024 elementos, su contenido se vuelca al fichero CSV y se vacía para liberar memoria. Este procedimiento se repite hasta procesar todos los paquetes, momento en el que se realiza un último volcado con los datos restantes. Se ha optado por este método de lectura y escritura para optimizar tanto el uso de memoria como la frecuencia de accesos de escritura al disco.

Los ficheros PCAP correspondientes al tráfico de ransomware fueron obtenidos, tal y como se explica en el apartado 2.1 por el trabajo de Eduardo Berrueta et al. entre los años 2015 y 2022\cite{qnyn-q136-20}. Por otro lado, el fichero PCAP con tráfico legítimo fue generado por el autor mediante la captura de tráfico durante una jornada laboral en un laboratorio universitario, registrando el uso normal de los dispositivos y recogiendo tráfico de protocolos como HTTP, HTTPS, DNS, SSH, entre otros. Con el objetivo de incrementar la precisión del árbol de decisión, se generó adicionalmente tráfico SMB2 mediante la copia de un fichero de gran tamaño a una unidad de almacenamiento ubicada en el CPD de la universidad.

En el proceso de preparación del dataset, se eliminaron las direcciones IP, las direcciones MAC y el timestamp de los paquetes, debido al número limitado presente tanto en las capturas de tráfico malicioso como en las de tráfico legítimo. Con ello, se evitó que el árbol de decisión se apoyara en características poco representativas o irrelevantes para un entorno real. Como métrica de calidad se mantuvo el índice de Gini, dada su fiabilidad y buen rendimiento, y como estrategia de división se empleó el criterio best. Aunque se preveía que el aumento del tamaño del dataset respecto a las pruebas podría incrementar el tiempo de entrenamiento, en la práctica no se observó un impacto significativo. En caso contrario, se habría considerado cambiar la estrategia a random. En cuanto a la profundidad máxima del árbol, se fijó inicialmente en cuatro niveles, ya que en pruebas previas con otros datasets de paquetes de red no se apreciaron mejoras de precisión al superar este valor.

Para entrenar el árbol de decisión, una vez definidas las columnas que serán eliminadas, se establece la variable x como el conjunto de columnas que forman parte de los datos de entrada y la variable y como la columna correspondiente al clasificador. A continuación, mediante la función train\_test\_split, se divide el conjunto de datos de forma aleatoria, asignando el 80\% de las filas al entrenamiento y el 20\% restante a las pruebas, con el fin de evaluar la fiabilidad del modelo. Una vez realizada esta partición, se procede a entrenar el árbol utilizando los parámetros seleccionados y los datos de entrenamiento. Finalmente, se puede calcular la exactitud del modelo, si bien es recomendable interpretar este valor con cautela, dado que no siempre refleja de forma completamente sólida la capacidad de generalización del clasificador. El código correspondiente al entrenamiento del árbol puede consultarse en \ref{entrenamientoArbol}

Durante el desarrollo, se detectó que, por error, se había incluido la variable eth\_type en la lista de columnas excluidas del entrenamiento. Tras corregir esta omisión y volver a entrenar el modelo, se observó que la precisión se mantenía, pero esta vez con un nivel menos de profundidad, alcanzando una profundidad máxima de tres niveles a pesar de que el límite establecido era de cuatro. Este resultado sugiere que la inclusión de dicha variable aporta capacidad predictiva al modelo, optimizando su estructura sin pérdida de precisión.

\PythonCode[pcap2dict]{PCAP a Dict}{Fragmento de códgio que transforma parte de los datos de un paquete en un diccionario fácilmente convertible a CSV.}{../../DecisionTree/pcap2csv.py}{39}{60}{39}

\PythonCode[entrenamientoArbol]{Entrenamiento Árbol}{Fragmento de códgio de arbolrw.py encargado de entrenar el árbol de decisión.}{../../DecisionTree/arbolrw.py}{82}{111}{82}

\subsection{Código XDP y Código autogenerado}
Se añadió la capacidad de autogenerar el código BPF/XDP una vez entrenado el árbol de decisión. Para ello, se recorre de forma recursiva el árbol y, en cada nodo, se genera la condición correspondiente a partir del nombre de la característica (previamente convertido a su nombre real) y del valor de umbral. Esta condición se pasa por una función que, en determinados casos, la sustituye por una equivalente válida. Por ejemplo, la condición src\_port <= inf se reemplaza por ip\_proto == IPPROTO\_TCP || ip\_proto == IPPROTO\_UDP, dado que el hecho de que el puerto de destino sea menor que infinito únicamente implica que el puerto existe.

Cuando la condición resultante es válida, si corresponde al hijo izquierdo del nodo se inserta en una estructura if, mientras que si corresponde al hijo derecho se inserta en una estructura else. Para la generación del código se empleó una plantilla Jinja con la estructura prediseñada en C. Durante las pruebas, se observó que el mejor resultado se obtenía extrayendo los datos de las cabeceras IP antes de la evaluación del árbol, de forma que ya estuvieran disponibles en la plantilla. En caso de que el paquete analizado carezca de cabecera IP, dichos valores se establecen en cero.
